{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": "Food101_32classes_Modet_training.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWW0fzlM0JS5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6616604-dd11-4569-f3bd-677a4a0160a8"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import matplotlib.image as img\n",
        "from keras.backend.tensorflow_backend import set_session\n",
        "config = tf.ConfigProto(allow_soft_placement=True)\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 1\n",
        "config.gpu_options.allow_growth = True\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, TensorBoard"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOhp50GR0JS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = 'train.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('train')\n",
        "local_zip = 'test.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('test')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e21B4XKd0JS_",
        "colab_type": "code",
        "outputId": "ed290487-586d-46d0-d7a3-16f59f37b02d",
        "colab": {}
      },
      "source": [
        "K.clear_session()\n",
        "sess = tf.Session(config=config)\n",
        "for d in ['/device:GPU:2', '/device:GPU:3']:\n",
        "    with tf.device(d):\n",
        "        nb_train_samples = 32*750\n",
        "        nb_validation_samples = 32*250\n",
        "        batch_size = 128\n",
        "        # All images will be rescaled by 1./255\n",
        "        train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "            # Augmentation techiques                               \n",
        "            shear_range=30,\n",
        "            zoom_range=0.5,\n",
        "            fill_mode='constant',\n",
        "            rotation_range=90,\n",
        "            width_shift_range=.2,\n",
        "            height_shift_range=.2, \n",
        "            horizontal_flip=True)\n",
        "            vertical_flip=True,\n",
        "            channel_shift_range=100,\n",
        "            brightness_range=[0.5,1.0],\n",
        "            zca_whitening=True)\n",
        "        validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "        # Flow training images in batches of 64 using train_datagen generator\n",
        "        train_generator = train_datagen.flow_from_directory(\n",
        "                'train/train/',  # This is the source directory for training images\n",
        "                target_size=(224, 224),  # All images will be resized to 150x150\n",
        "                batch_size = batch_size,\n",
        "                # Since we use binary_crossentropy loss, we need binary labels\n",
        "                class_mode='categorical')\n",
        "\n",
        "        # Flow training images in batches of 128 using train_datagen generator\n",
        "        validation_generator = validation_datagen.flow_from_directory(\n",
        "                'test/test/',  # This is the source directory for training images\n",
        "                target_size=(224, 224),  # All images will be resized to 150x150\n",
        "                batch_size = batch_size,\n",
        "                # Since we use binary_crossentropy loss, we need binary labels\n",
        "                class_mode='categorical')\n",
        "        inception = MobileNetV2(weights='imagenet', include_top=False, input_shape = (224,224,3))\n",
        "        #for layer in inception.layers: --- Freez layers\n",
        "        #  layer.trainable = False\n",
        "        x = inception.output\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "        x = Dense(128,activation='relu')(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "\n",
        "        predictions = Dense(32,kernel_regularizer=regularizers.l2(0.005), activation='softmax')(x)\n",
        "        model = Model(inputs=inception.input, outputs=predictions)\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=SGD(lr=0.001, momentum=0.9, decay=0.001), metrics=['accuracy'])\n",
        "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='MobileNetV2_32classes.hdf5', verbose=1, monitor='val_loss', save_best_only=True)\n",
        "csv_logger = CSVLogger('history_MobileNetv2_32classes.log')\n",
        "es = EarlyStopping(monitor='val_acc', mode='max', patience=10, verbose=1, baseline=None)\n",
        "tb = TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=64, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 24000 images belonging to 32 classes.\n",
            "Found 8000 images belonging to 32 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaEN8Y6e0JTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfZgZMHu0JTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch = nb_train_samples // batch_size,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps = nb_validation_samples // batch_size,  \n",
        "      epochs=80,\n",
        "      verbose=1,\n",
        "      callbacks=[csv_logger, checkpointer, es, tb]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Qb7Vn2P60JTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_accuracy(history,title):\n",
        "    plt.title(title)\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_accuracy', 'validation_accuracy'], loc='best')\n",
        "    plt.show()\n",
        "def plot_loss(history,title):\n",
        "    plt.title(title)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_loss', 'validation_loss'], loc='best')\n",
        "    plt.show()\n",
        "plot_accuracy(history,'FOOD101_32 classes')\n",
        "plot_loss(history,'FOOD101_32 classes')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}